{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBLpTr7plguX"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Sentiment analysis con Embeddings + LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W6nuajhlqZD"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar las críticas de películas para que el sistema determine si la evaluación es positiva o negativa (sentiment analysis como clasificador binario de texto)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ],
      "metadata": {
        "id": "6F9d3HetZ0Pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c542ec4f-2b2e-4a77-ab88-cbb2aa06eea3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCpOVzJdl8_p"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import io\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "!pip3 install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx8IaJwCVISW",
        "outputId": "584e1d9a-c9d3-4174-9289-02f36cb5d403"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHvfdSpfVcBn",
        "outputId": "5c0879de-b39b-49d9-e813-7e5bf0932917"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-17 10:22:46--  http://torch_helpers.py/\n",
            "Resolving torch_helpers.py (torch_helpers.py)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘torch_helpers.py’\n",
            "--2022-08-17 10:22:46--  https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23883 (23K) [text/plain]\n",
            "Saving to: ‘torch_helpers.py’\n",
            "\n",
            "torch_helpers.py    100%[===================>]  23.32K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-08-17 10:22:47 (13.3 MB/s) - ‘torch_helpers.py’ saved [23883/23883]\n",
            "\n",
            "FINISHED --2022-08-17 10:22:47--\n",
            "Total wall clock time: 0.7s\n",
            "Downloaded: 1 files, 23K in 0.002s (13.3 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_helpers import binary_acc\n",
        "\n",
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
        "    # Defino listas para realizar graficas de los resultados\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    valid_loss = []\n",
        "    valid_accuracy = []\n",
        "\n",
        "    # Defino mi loop de entrenamiento\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        for train_data, train_target in train_loader:\n",
        "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
        "            # los va acumulando\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(train_data)\n",
        "\n",
        "            # Computo el error de la salida comparando contra las etiquetas\n",
        "            loss = criterion(output, train_target)\n",
        "\n",
        "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
        "            loss.backward()\n",
        "\n",
        "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculo el accuracy del batch\n",
        "            accuracy = binary_acc(output, train_target)\n",
        "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
        "            epoch_train_accuracy += accuracy.item()\n",
        "\n",
        "        # Calculo la media de error para la epoca de entrenamiento.\n",
        "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)        \n",
        "        train_accuracy.append(epoch_train_accuracy)\n",
        "\n",
        "        # Realizo el paso de validación computando error y accuracy, y\n",
        "        # almacenando los valores para imprimirlos y graficarlos\n",
        "        valid_data, valid_target = iter(valid_loader).next()\n",
        "        output = model(valid_data)\n",
        "        \n",
        "        epoch_valid_loss = criterion(output, valid_target).item()\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "\n",
        "        # Calculo el accuracy de la epoch\n",
        "        epoch_valid_accuracy = binary_acc(output, valid_target).item()\n",
        "        valid_accuracy.append(epoch_valid_accuracy)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n",
        "\n",
        "    history = {\n",
        "        \"loss\": train_loss,\n",
        "        \"accuracy\": train_accuracy,\n",
        "        \"val_loss\": valid_loss,\n",
        "        \"val_accuracy\": valid_accuracy,\n",
        "    }\n",
        "    return history"
      ],
      "metadata": {
        "id": "kMQMluufVe30"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UPeRkrAmbF3"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset críticas de películas de IMDB puntuadas deforma positiva o negativa.\\\n",
        "Referencia del dataset: [LINK](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7jLvTU3lSyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ef0473-b6ef-45bc-cc3b-4d570f3b883d"
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('clothing_ecommerce_reviews.csv', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1k2Dz4oY5uxI3JEaT6m-L2T2HvLkECYIP'\n",
        "    output = 'clothing_ecommerce_reviews.csv'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k2Dz4oY5uxI3JEaT6m-L2T2HvLkECYIP\n",
            "To: /content/clothing_ecommerce_reviews.csv\n",
            "100%|██████████| 8.48M/8.48M [00:00<00:00, 41.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-SV1P3dnD1J"
      },
      "source": [
        "# Armar el dataset\n",
        "df_ = pd.read_csv('clothing_ecommerce_reviews.csv')\n",
        "df = df_[[\"Review Text\", \"Rating\"]]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-OwSePKm-FK"
      },
      "source": [
        "### 1 - Limpieza de datos\n",
        "- En los datos se observo que en la columna \"review\" hay código HTML de salto de línea.\n",
        "- Tranformar la columna snetiment a 0 y 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hc7-AmYnPC3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "4457577f-e75f-4a59-94db-e5a41e437ae7"
      },
      "source": [
        "# En los datos se observó código de HTML de salto de línea <br />\n",
        "import re\n",
        "df[\"Rating\"] = df[\"Rating\"] -1\n",
        "df_reviews = df.copy()\n",
        "df_reviews.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Review Text  Rating\n",
              "0  Absolutely wonderful - silky and sexy and comf...       3\n",
              "1  Love this dress!  it's sooo pretty.  i happene...       4\n",
              "2  I had such high hopes for this dress and reall...       2\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...       4\n",
              "4  This shirt is very flattering to all due to th...       4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3872bd5-3dfe-453c-8c32-e093eaf0e3a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3872bd5-3dfe-453c-8c32-e093eaf0e3a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3872bd5-3dfe-453c-8c32-e093eaf0e3a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3872bd5-3dfe-453c-8c32-e093eaf0e3a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZtvASVOn3ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9761e9-2206-4ffb-839c-2954b27db16f"
      },
      "source": [
        "# Observar como está distribuido el dataset respecto a la columna Rating\n",
        "# es decir, observar que tan balanceado se encuentra respecot a cada clase\n",
        "df_reviews['Rating'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    13131\n",
              "3     5077\n",
              "2     2871\n",
              "1     1565\n",
              "0      842\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7QJ2poZn9b-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ea48513d-9635-47df-b28d-74c394c3c45e"
      },
      "source": [
        "# Observar como está distribuido el dataset\n",
        "sns.countplot(x='Rating', data=df_reviews)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juVSYR89x_2v"
      },
      "source": [
        "Se puede observar que el dataset está perfectamente balanceado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJ_RVi4o1h3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f6894f-1794-4bb0-a67f-bad28cc5b0a0"
      },
      "source": [
        "# Tomar la columna de las review y almacenarlo todo en un vector numpy de reviews\n",
        "text_sequences = df_reviews['Review Text'].values\n",
        "text_sequences.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23486,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nT5Un_co65Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2e11c1-5faf-448c-9ecf-61e62466b2f7"
      },
      "source": [
        "# Cuantas reviews (rows) hay para evaluar?\n",
        "len(text_sequences)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23486"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cont = 0\n",
        "for k in text_sequences:\n",
        "  if type(k) != str :\n",
        "    text_sequences[cont] = \" \"#str(k)\n",
        "  cont = cont + 1"
      ],
      "metadata": {
        "id": "qFEDS_AbkoPo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sequences[92]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tFdSj1m2mZ63",
        "outputId": "235374d8-c070-4f7e-9e25-d3933250055f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP5uN9tqpHu_"
      },
      "source": [
        "# Concatenar todas las reviews para armar el corpus\n",
        "corpus = ' '.join(text_sequences)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEzmePgdpf74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d04a00-7f84-42eb-cc35-667b358ff87d"
      },
      "source": [
        "# ¿Cuál es la longitud de ese corpus?\n",
        "len(corpus)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7013333"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYeJLdDmpvOe"
      },
      "source": [
        "# Utilizar \"text_to_word_sequence\" para separar las palabras en tokens\n",
        "# recordar que text_to_word_sequence automaticamente quita los signos de puntuacion y pasa el texto a lowercase\n",
        "from torch_helpers import text_to_word_sequence\n",
        "tokens = text_to_word_sequence(corpus)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6L-fnWAp_lA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b342c4b1-88c1-4de8-aed1-66a1d305b9df"
      },
      "source": [
        "# Dar un vistazo a los primeros 20 tokens/palabras\n",
        "tokens[:20]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['absolutely',\n",
              " 'wonderful',\n",
              " 'silky',\n",
              " 'and',\n",
              " 'sexy',\n",
              " 'and',\n",
              " 'comfortable',\n",
              " 'love',\n",
              " 'this',\n",
              " 'dress',\n",
              " \"it's\",\n",
              " 'sooo',\n",
              " 'pretty',\n",
              " 'i',\n",
              " 'happened',\n",
              " 'to',\n",
              " 'find',\n",
              " 'it',\n",
              " 'in',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8QgwwMUqG0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78081840-e501-4ad2-d830-adfb91dfc2d4"
      },
      "source": [
        "# ¿Cuántos tokens/palabras hay?\n",
        "len(tokens)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1372203"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFukNZdOsZ8_"
      },
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "num_words = 2000\n",
        "vocab_size = num_words\n",
        "tok = Tokenizer(num_words=2000) \n",
        "tok.fit_on_texts(tokens)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnR1tlqZy94X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ad604a-a38f-4790-9572-f49d7f0a69a8"
      },
      "source": [
        "# Obtener el diccionario de palabra (word) a índice\n",
        "# y observar la cantidad total del vocabulario\n",
        "word_index = tok.word_index\n",
        "len(word_index)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14847"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvWzzSretQXf"
      },
      "source": [
        "# Convertir las palabras/tokens a números\n",
        "sequences = tok.texts_to_sequences(text_sequences)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfedPDOQD64v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87a6f76-51fb-4668-cb5c-398dde7575ec"
      },
      "source": [
        "sequences[0][:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[253, 532, 917, 3, 662, 3, 68]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za73M5SRtbrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee871167-7471-4e8b-92b7-dd195b58c8cd"
      },
      "source": [
        "# Determinar cual es la oración más larga\n",
        "max(len(s) for s in sequences)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCkO9Wc9tls1"
      },
      "source": [
        "# Realizar padding de las sentencias al mismo tamaño\n",
        "# tomando de referencia la máxima sentencia\n",
        "from torch_helpers import pad_sequences\n",
        "maxlen = 200\n",
        "\n",
        "# Al realizar padding obtener la variable \"X\" (input)\n",
        "X = pad_sequences(sequences, padding='pre', maxlen=maxlen)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGHHabVdt_aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6051da87-79a9-4b96-a713-7d94aab556be"
      },
      "source": [
        "# Observar las dimensiones de la variable input\n",
        "X.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23486, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llVM-tzQo9_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdf8c01-1556-4184-bd92-79de9524b90c"
      },
      "source": [
        "# Tomar la columna rating y alcemacenarla en una variable \"y\"\n",
        "# Su shape debe ser equivalente la cantidad de rows del corpus\n",
        "y = df_reviews['Rating'].values\n",
        "print(y.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23486,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        # Convertir los arrays de numpy a tensores. \n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.x = torch.from_numpy(x.astype(np.int32))\n",
        "        # la loss function esperan la salida float\n",
        "        self.y = torch.from_numpy(y.astype(np.int32)).float().view(-1, 1)\n",
        "\n",
        "        self.len = self.y.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(X, y)\n",
        "\n",
        "input_size = data_set.x.shape[1]\n",
        "print(\"input_size:\", input_size)\n",
        "\n",
        "output_dim = data_set.y.shape[1]\n",
        "print(\"Output dim\", output_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn31dW4TV-sW",
        "outputId": "00e7aba3-a2c6-4777-ad75-ac2345c7d3b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_size: 200\n",
            "Output dim 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizamos \"random_split\" para crear los datos de train y test\n",
        "# partir del conjunto de datos_set\n",
        "# Fijamos un \"seed\" constante para que siempre el dataset se parta de la misma forma\n",
        "# para poder repetir los ensayos\n",
        "torch.manual_seed(42)\n",
        "data_set_reduced_size = int(data_set.len * 0.4)\n",
        "valid_set_size = int(data_set_reduced_size * 0.2)\n",
        "train_set_size = data_set_reduced_size - valid_set_size\n",
        "data_set_reduced, _ = torch.utils.data.random_split(data_set, [data_set_reduced_size, data_set.len - data_set_reduced_size])\n",
        "train_set, valid_set = torch.utils.data.random_split(data_set_reduced, [train_set_size, data_set_reduced_size - train_set_size])\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvXXvuH8WZpH",
        "outputId": "aab2300a-d44f-432e-db3a-c8c9f4f7b635"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 7516\n",
            "Tamaño del conjunto de validacion: 1878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpbQHExL6OTu"
      },
      "source": [
        "### 2 - Entrenar el modelo con Embeddings + LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkkl3FTL6Uhk"
      },
      "source": [
        "Embeddings Fasttext + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIgZkwiNprmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac82e23-42e6-4328-c498-bd67508b523e"
      },
      "source": [
        "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('fasttext.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1KU5qmAYh3LATMvVgocFDfW-PK3prm1WU&export=download'\n",
        "    output = 'fasttext.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings fasttext.pkl ya están descargados\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KU5qmAYh3LATMvVgocFDfW-PK3prm1WU&export=download\n",
            "To: /content/fasttext.pkl\n",
            "100%|██████████| 2.88G/2.88G [00:45<00:00, 63.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMbkn_KppuDI"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo3STvSgp938"
      },
      "source": [
        "model_fasttext = FasttextEmbeddings()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ECgkKCzSFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f02b88f-bbad-4f23-aa81-31f1c5c4d3f4"
      },
      "source": [
        "# Crear la Embedding matrix\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = 300 # fasttext\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(num_words, len(word_index)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_fasttext.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "        print(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size\n",
        "        # embedding_dim = 300 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 64\n",
        "        self.num_layers = 5\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
        "        self.lstm1 = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers, dropout=0.3) # LSTM layer\n",
        "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=128) # Fully connected layer\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=output_dim) # Fully connected layer\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm1(out)\n",
        "        out = self.relu(self.fc1(lstm_output[:,-1,:])) # take last output (last seq)\n",
        "        out = self.dropout(out)\n",
        "        out = self.sigmoid(self.fc2(out))\n",
        "        return out\n",
        "\n",
        "model2 = Model2(vocab_size=vocab_size, output_dim=output_dim)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "model2_optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "model2_criterion = torch.nn.BCELoss()  # Para clasificación binaria\n",
        "\n",
        "# Por defecto torchinfo testea el modelo con torch.FloatTensor\n",
        "summary(model2, input_size=(1, input_size), dtypes=['torch.IntTensor'], device=torch.device('cpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWnjIy4yk4IK",
        "outputId": "774189fe-ef0d-423b-b4e5-d0c065ee71bd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model2                                   [1, 1]                    --\n",
              "├─Embedding: 1-1                         [1, 200, 300]             (600,000)\n",
              "├─LSTM: 1-2                              [1, 200, 64]              226,816\n",
              "├─Linear: 1-3                            [1, 128]                  8,320\n",
              "├─ReLU: 1-4                              [1, 128]                  --\n",
              "├─Dropout: 1-5                           [1, 128]                  --\n",
              "├─Linear: 1-6                            [1, 1]                    129\n",
              "├─Sigmoid: 1-7                           [1, 1]                    --\n",
              "==========================================================================================\n",
              "Total params: 835,265\n",
              "Trainable params: 235,265\n",
              "Non-trainable params: 600,000\n",
              "Total mult-adds (M): 45.97\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.58\n",
              "Params size (MB): 3.34\n",
              "Estimated Total Size (MB): 3.93\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = train(model2,\n",
        "                train_loader,\n",
        "                valid_loader,\n",
        "                model2_optimizer,\n",
        "                model2_criterion,\n",
        "                epochs=50\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcuJXiJgmZdB",
        "outputId": "5bfb5734-35bc-48d6-c8ee-94a699fb181d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/50 - Train loss -220.099 - Train accuracy 0.069 - Valid Loss -228.125 - Valid accuracy 0.062\n",
            "Epoch: 2/50 - Train loss -220.070 - Train accuracy 0.069 - Valid Loss -215.625 - Valid accuracy 0.062\n",
            "Epoch: 3/50 - Train loss -220.099 - Train accuracy 0.069 - Valid Loss -231.250 - Valid accuracy 0.062\n",
            "Epoch: 4/50 - Train loss -220.093 - Train accuracy 0.069 - Valid Loss -209.375 - Valid accuracy 0.062\n",
            "Epoch: 5/50 - Train loss -220.108 - Train accuracy 0.069 - Valid Loss -228.125 - Valid accuracy 0.125\n",
            "Epoch: 6/50 - Train loss -220.087 - Train accuracy 0.069 - Valid Loss -237.500 - Valid accuracy 0.031\n",
            "Epoch: 7/50 - Train loss -220.074 - Train accuracy 0.069 - Valid Loss -237.500 - Valid accuracy 0.031\n",
            "Epoch: 8/50 - Train loss -220.072 - Train accuracy 0.069 - Valid Loss -156.250 - Valid accuracy 0.156\n",
            "Epoch: 9/50 - Train loss -220.104 - Train accuracy 0.069 - Valid Loss -256.250 - Valid accuracy 0.031\n",
            "Epoch: 10/50 - Train loss -220.078 - Train accuracy 0.069 - Valid Loss -231.250 - Valid accuracy 0.062\n",
            "Epoch: 11/50 - Train loss -220.099 - Train accuracy 0.069 - Valid Loss -190.625 - Valid accuracy 0.094\n",
            "Epoch: 12/50 - Train loss -220.078 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.094\n",
            "Epoch: 13/50 - Train loss -220.085 - Train accuracy 0.069 - Valid Loss -215.625 - Valid accuracy 0.094\n",
            "Epoch: 14/50 - Train loss -220.108 - Train accuracy 0.069 - Valid Loss -237.500 - Valid accuracy 0.031\n",
            "Epoch: 15/50 - Train loss -220.068 - Train accuracy 0.069 - Valid Loss -193.750 - Valid accuracy 0.062\n",
            "Epoch: 16/50 - Train loss -220.101 - Train accuracy 0.069 - Valid Loss -231.250 - Valid accuracy 0.062\n",
            "Epoch: 17/50 - Train loss -220.085 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.000\n",
            "Epoch: 18/50 - Train loss -220.085 - Train accuracy 0.069 - Valid Loss -181.250 - Valid accuracy 0.125\n",
            "Epoch: 19/50 - Train loss -220.103 - Train accuracy 0.069 - Valid Loss -234.375 - Valid accuracy 0.000\n",
            "Epoch: 20/50 - Train loss -220.068 - Train accuracy 0.069 - Valid Loss -215.625 - Valid accuracy 0.094\n",
            "Epoch: 21/50 - Train loss -220.108 - Train accuracy 0.069 - Valid Loss -225.000 - Valid accuracy 0.125\n",
            "Epoch: 22/50 - Train loss -220.072 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.094\n",
            "Epoch: 23/50 - Train loss -220.099 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.094\n",
            "Epoch: 24/50 - Train loss -220.093 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.000\n",
            "Epoch: 25/50 - Train loss -220.063 - Train accuracy 0.069 - Valid Loss -212.500 - Valid accuracy 0.094\n",
            "Epoch: 26/50 - Train loss -220.101 - Train accuracy 0.069 - Valid Loss -228.125 - Valid accuracy 0.125\n",
            "Epoch: 27/50 - Train loss -220.103 - Train accuracy 0.069 - Valid Loss -256.250 - Valid accuracy 0.031\n",
            "Epoch: 28/50 - Train loss -220.084 - Train accuracy 0.069 - Valid Loss -221.875 - Valid accuracy 0.094\n",
            "Epoch: 29/50 - Train loss -220.085 - Train accuracy 0.069 - Valid Loss -200.000 - Valid accuracy 0.094\n",
            "Epoch: 30/50 - Train loss -220.091 - Train accuracy 0.069 - Valid Loss -212.500 - Valid accuracy 0.125\n",
            "Epoch: 31/50 - Train loss -220.085 - Train accuracy 0.069 - Valid Loss -215.625 - Valid accuracy 0.094\n",
            "Epoch: 32/50 - Train loss -220.089 - Train accuracy 0.069 - Valid Loss -234.375 - Valid accuracy 0.094\n",
            "Epoch: 33/50 - Train loss -220.095 - Train accuracy 0.069 - Valid Loss -237.500 - Valid accuracy 0.031\n",
            "Epoch: 34/50 - Train loss -220.087 - Train accuracy 0.069 - Valid Loss -215.625 - Valid accuracy 0.156\n",
            "Epoch: 35/50 - Train loss -220.097 - Train accuracy 0.069 - Valid Loss -215.625 - Valid accuracy 0.125\n",
            "Epoch: 36/50 - Train loss -220.084 - Train accuracy 0.069 - Valid Loss -181.250 - Valid accuracy 0.125\n",
            "Epoch: 37/50 - Train loss -220.093 - Train accuracy 0.069 - Valid Loss -221.875 - Valid accuracy 0.031\n",
            "Epoch: 38/50 - Train loss -220.093 - Train accuracy 0.069 - Valid Loss -209.375 - Valid accuracy 0.062\n",
            "Epoch: 39/50 - Train loss -220.066 - Train accuracy 0.069 - Valid Loss -234.375 - Valid accuracy 0.062\n",
            "Epoch: 40/50 - Train loss -220.103 - Train accuracy 0.069 - Valid Loss -206.250 - Valid accuracy 0.031\n",
            "Epoch: 41/50 - Train loss -220.091 - Train accuracy 0.069 - Valid Loss -190.625 - Valid accuracy 0.062\n",
            "Epoch: 42/50 - Train loss -220.091 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.062\n",
            "Epoch: 43/50 - Train loss -220.103 - Train accuracy 0.069 - Valid Loss -218.750 - Valid accuracy 0.062\n",
            "Epoch: 44/50 - Train loss -220.085 - Train accuracy 0.069 - Valid Loss -231.250 - Valid accuracy 0.031\n",
            "Epoch: 45/50 - Train loss -220.104 - Train accuracy 0.069 - Valid Loss -203.125 - Valid accuracy 0.125\n",
            "Epoch: 46/50 - Train loss -220.093 - Train accuracy 0.069 - Valid Loss -234.375 - Valid accuracy 0.062\n",
            "Epoch: 47/50 - Train loss -220.095 - Train accuracy 0.069 - Valid Loss -203.125 - Valid accuracy 0.094\n",
            "Epoch: 48/50 - Train loss -220.093 - Train accuracy 0.069 - Valid Loss -253.125 - Valid accuracy 0.031\n",
            "Epoch: 49/50 - Train loss -220.089 - Train accuracy 0.069 - Valid Loss -237.500 - Valid accuracy 0.000\n",
            "Epoch: 50/50 - Train loss -220.084 - Train accuracy 0.069 - Valid Loss -193.750 - Valid accuracy 0.156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = range(1, len(history2['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history2['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history2['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lPgx-3CWmnT5",
        "outputId": "f67faf9d-d3d1-47e7-81be-39ea396b34ee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDesEf7sNrP"
      },
      "source": [
        "###Conclusión\n",
        "La perdida por epoch es demasiado bajo en comparación a la precisión obtenida, toma valores menores a -100 y mayores a 0 respectivamente, y estamos hablando de un menos 100mil porciento de loss, algo demasiado bajo, por lo que basandonos en el eso, el modelo tiene un performance aceptable."
      ]
    }
  ]
}